{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Installation and Setup</h1>\n",
    "This is where all installations of third party libraries to require us the dependencies we need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\Jayra\\AppData\\Local\\Temp\\pip-req-build-sojnytxj'\n",
      "WARNING: You are using pip version 21.1.2; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Jayra\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\jayra\\appdata\\local\\temp\\pip-req-build-sojnytxj\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from snscrape==0.4.3.20220107.dev56+gd72b519) (2.25.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from snscrape==0.4.3.20220107.dev56+gd72b519) (4.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from snscrape==0.4.3.20220107.dev56+gd72b519) (4.9.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from snscrape==0.4.3.20220107.dev56+gd72b519) (3.4.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from beautifulsoup4->snscrape==0.4.3.20220107.dev56+gd72b519) (2.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev56+gd72b519) (1.26.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev56+gd72b519) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev56+gd72b519) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev56+gd72b519) (2021.5.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev56+gd72b519) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imports</h1>\n",
    "The following tools are what we need to use in order to scrape & check the nature of the data we want to explore in Twitter(IN our case, it is disaster related and it is within a specific location).\n",
    "\n",
    "<h4>Goals</h4>\n",
    "The goal of this section is the following:\n",
    "\n",
    "* To Get A Content Related to Disaster and Risk Management\n",
    "* To Get data ranging from different locations (for comparison)\n",
    "* To save the file and observe in the next section \n",
    "* Enumerate our findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools\n",
    "\n",
    "# Natural Disasters\n",
    "\n",
    "df_forest_fire_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"forest fire\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_forest_fire_en[\"keyword\"] = 0\n",
    "\n",
    "df_deforestation_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"deforestation\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_forest_fire_en[\"keyword\"] = 0\n",
    "\n",
    "\n",
    "df_flood_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"flash flood\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_flood_en[\"keyword\"] = 1\n",
    "\n",
    "df_floodrain_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"heavy rainfall\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_flood_en[\"keyword\"] = 1\n",
    "\n",
    "df_floodwater_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"rising water\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_flood_en[\"keyword\"] = 1\n",
    "\n",
    "df_floodpour_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"downpour\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_flood_en[\"keyword\"] = 1\n",
    "\n",
    "df_eruption_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"volcanic eruption\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_eruption_en[\"keyword\"] = 2\n",
    "\n",
    "df_eruptionflow_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"pyroclastic flow\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_eruption_en[\"keyword\"] = 2\n",
    "\n",
    "df_aftershock_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"aftershock\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_aftershock_en[\"keyword\"] = 3\n",
    "\n",
    "df_earthquake_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"earthquake\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_earthquake_en[\"keyword\"] = 3\n",
    "\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools\n",
    "\n",
    "# Natural Disasters\n",
    "\n",
    "df_forest_fire_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"forest fire\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_forest_fire_en[\"keyword\"] = 0\n",
    "\n",
    "df_deforestation_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"deforestation\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_deforestation_en[\"keyword\"] = 0\n",
    "\n",
    "\n",
    "df_flood_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"flash flood\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_flood_en[\"keyword\"] = 1\n",
    "\n",
    "df_floodrain_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"heavy rainfall\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_floodrain_en[\"keyword\"] = 1\n",
    "\n",
    "df_floodwater_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"rising water\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_floodwater_en[\"keyword\"] = 1\n",
    "\n",
    "df_floodpour_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"downpour\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_floodpour_en[\"keyword\"] = 1\n",
    "\n",
    "df_eruption_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"volcanic eruption\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_eruption_en[\"keyword\"] = 2\n",
    "\n",
    "df_eruptionflow_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"pyroclastic flow\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_eruptionflow_en[\"keyword\"] = 2\n",
    "\n",
    "df_aftershock_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"aftershock\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_aftershock_en[\"keyword\"] = 3\n",
    "\n",
    "df_earthquake_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"earthquake\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_earthquake_en[\"keyword\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_flood_refugees_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"flood refugees\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_flood_refugees_en[\"keyword\"] = 4\n",
    "\n",
    "df_earthquake_refugees_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"earthquake refuge\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_earthquake_refugees_en[\"keyword\"] = 4\n",
    "\n",
    "df_bunker_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"bunker\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_bunker_en[\"keyword\"] = 4\n",
    "\n",
    "df_crop_drought_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"climate change\" lang:en').get_items(), 2000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_crop_drought_en[\"keyword\"] = 5\n",
    "\n",
    "df_tropical_cyclone_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"tropical cyclone\" lang:en').get_items(), 1000))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_tropical_cyclone_en[\"keyword\"] = 6\n",
    "\n",
    "df_typhoon_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"typhoon\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_typhoon_en[\"keyword\"] = 6\n",
    "\n",
    "df_hurricane_en = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"hurricane\" lang:en').get_items(), 500))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_hurricane_en[\"keyword\"] = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           1000 non-null   object             \n",
      " 1   date          1000 non-null   datetime64[ns, UTC]\n",
      " 2   rawContent    1000 non-null   object             \n",
      " 3   sourceLabel   1000 non-null   object             \n",
      " 4   retweetCount  1000 non-null   int64              \n",
      " 5   user          1000 non-null   object             \n",
      " 6   keyword       1000 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           500 non-null    object             \n",
      " 1   date          500 non-null    datetime64[ns, UTC]\n",
      " 2   rawContent    500 non-null    object             \n",
      " 3   sourceLabel   500 non-null    object             \n",
      " 4   retweetCount  500 non-null    int64              \n",
      " 5   user          500 non-null    object             \n",
      " 6   keyword       500 non-null    int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 27.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           1000 non-null   object             \n",
      " 1   date          1000 non-null   datetime64[ns, UTC]\n",
      " 2   rawContent    1000 non-null   object             \n",
      " 3   sourceLabel   1000 non-null   object             \n",
      " 4   retweetCount  1000 non-null   int64              \n",
      " 5   user          1000 non-null   object             \n",
      " 6   keyword       1000 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           1000 non-null   object             \n",
      " 1   date          1000 non-null   datetime64[ns, UTC]\n",
      " 2   rawContent    1000 non-null   object             \n",
      " 3   sourceLabel   1000 non-null   object             \n",
      " 4   retweetCount  1000 non-null   int64              \n",
      " 5   user          1000 non-null   object             \n",
      " 6   keyword       1000 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           1000 non-null   object             \n",
      " 1   date          1000 non-null   datetime64[ns, UTC]\n",
      " 2   rawContent    1000 non-null   object             \n",
      " 3   sourceLabel   1000 non-null   object             \n",
      " 4   retweetCount  1000 non-null   int64              \n",
      " 5   user          1000 non-null   object             \n",
      " 6   keyword       1000 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           101 non-null    object             \n",
      " 1   date          101 non-null    datetime64[ns, UTC]\n",
      " 2   rawContent    101 non-null    object             \n",
      " 3   sourceLabel   101 non-null    object             \n",
      " 4   retweetCount  101 non-null    int64              \n",
      " 5   user          101 non-null    object             \n",
      " 6   keyword       101 non-null    int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 5.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           2000 non-null   object             \n",
      " 1   date          2000 non-null   datetime64[ns, UTC]\n",
      " 2   rawContent    2000 non-null   object             \n",
      " 3   sourceLabel   2000 non-null   object             \n",
      " 4   retweetCount  2000 non-null   int64              \n",
      " 5   user          2000 non-null   object             \n",
      " 6   keyword       2000 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 109.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_forest_fire_en.info())\n",
    "print(df_flood_en.info())\n",
    "print(df_eruption_en.info())\n",
    "print(df_earthquake_en.info())\n",
    "print(df_flood_refugees_en.info())\n",
    "print(df_earthquake_refugees_en.info())\n",
    "print(df_crop_drought_en.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest_fire_en[\"location\"] = [user[\"location\"] for user in df_forest_fire_en[\"user\"]]\n",
    "df_deforestation_en[\"location\"] = [user[\"location\"] for user in df_deforestation_en[\"user\"]]\n",
    "df_flood_en[\"location\"] = [user[\"location\"] for user in df_flood_en[\"user\"]]\n",
    "df_floodrain_en[\"location\"] = [user[\"location\"] for user in df_floodrain_en[\"user\"]]\n",
    "df_floodwater_en[\"location\"] = [user[\"location\"] for user in df_floodwater_en[\"user\"]]\n",
    "df_floodpour_en[\"location\"] = [user[\"location\"] for user in df_floodpour_en[\"user\"]]\n",
    "df_eruption_en[\"location\"] = [user[\"location\"] for user in df_eruption_en[\"user\"]]\n",
    "df_eruptionflow_en[\"location\"] = [user[\"location\"] for user in df_eruptionflow_en[\"user\"]]\n",
    "df_aftershock_en[\"location\"] = [user[\"location\"] for user in df_aftershock_en[\"user\"]]\n",
    "df_earthquake_en[\"location\"] = [user[\"location\"] for user in df_earthquake_en[\"user\"]]\n",
    "df_flood_refugees_en[\"location\"] = [user[\"location\"] for user in df_flood_refugees_en[\"user\"]]\n",
    "df_bunker_en[\"location\"] = [user[\"location\"] for user in df_bunker_en[\"user\"]]\n",
    "df_earthquake_refugees_en[\"location\"] = [user[\"location\"] for user in df_earthquake_refugees_en[\"user\"]]\n",
    "df_crop_drought_en[\"location\"] = [user[\"location\"] for user in df_crop_drought_en[\"user\"]]\n",
    "df_tropical_cyclone_en[\"location\"] = [user[\"location\"] for user in df_tropical_cyclone_en[\"user\"]]\n",
    "df_typhoon_en[\"location\"] = [user[\"location\"] for user in df_typhoon_en[\"user\"]]\n",
    "df_hurricane_en[\"location\"] = [user[\"location\"] for user in df_hurricane_en[\"user\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>user</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/everyEarthquake/status/155...</td>\n",
       "      <td>2022-08-02 00:12:49+00:00</td>\n",
       "      <td>USGS reports a M-0.3 earthquake, 44 km ESE of ...</td>\n",
       "      <td>everyEarthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'everyEarthquake', 'id': 14146844...</td>\n",
       "      <td>3</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/earthquake247/status/15542...</td>\n",
       "      <td>2022-08-02 00:12:47+00:00</td>\n",
       "      <td>#Earthquake of magnitude 4.6 at #Fiji_region. ...</td>\n",
       "      <td>bharatquake</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'earthquake247', 'id': 1291969748...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/TodoTiempo/status/15542588...</td>\n",
       "      <td>2022-08-02 00:12:32+00:00</td>\n",
       "      <td>Temblor -  M 4.6 - Fiji region https://t.co/sq...</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'TodoTiempo', 'id': 536561965, 'd...</td>\n",
       "      <td>3</td>\n",
       "      <td>San Juan PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/bobtimmermann/status/15542...</td>\n",
       "      <td>2022-08-02 00:12:11+00:00</td>\n",
       "      <td>@DavidYoungTBLA @SamSokol42 I am the opposite....</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'bobtimmermann', 'id': 17353087, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>California, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/earthshook/status/15542587...</td>\n",
       "      <td>2022-08-02 00:12:08+00:00</td>\n",
       "      <td>Mb 4.6 earthquake (reviewed) occured at 2022-0...</td>\n",
       "      <td>Quake Reporter</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'earthshook', 'id': 107816182, 'd...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://twitter.com/everyEarthquake/status/155...   \n",
       "1  https://twitter.com/earthquake247/status/15542...   \n",
       "2  https://twitter.com/TodoTiempo/status/15542588...   \n",
       "3  https://twitter.com/bobtimmermann/status/15542...   \n",
       "4  https://twitter.com/earthshook/status/15542587...   \n",
       "\n",
       "                       date  \\\n",
       "0 2022-08-02 00:12:49+00:00   \n",
       "1 2022-08-02 00:12:47+00:00   \n",
       "2 2022-08-02 00:12:32+00:00   \n",
       "3 2022-08-02 00:12:11+00:00   \n",
       "4 2022-08-02 00:12:08+00:00   \n",
       "\n",
       "                                          rawContent         sourceLabel  \\\n",
       "0  USGS reports a M-0.3 earthquake, 44 km ESE of ...     everyEarthquake   \n",
       "1  #Earthquake of magnitude 4.6 at #Fiji_region. ...         bharatquake   \n",
       "2  Temblor -  M 4.6 - Fiji region https://t.co/sq...             dlvr.it   \n",
       "3  @DavidYoungTBLA @SamSokol42 I am the opposite....  Twitter for iPhone   \n",
       "4  Mb 4.6 earthquake (reviewed) occured at 2022-0...      Quake Reporter   \n",
       "\n",
       "   retweetCount                                               user  keyword  \\\n",
       "0             0  {'username': 'everyEarthquake', 'id': 14146844...        3   \n",
       "1             0  {'username': 'earthquake247', 'id': 1291969748...        3   \n",
       "2             0  {'username': 'TodoTiempo', 'id': 536561965, 'd...        3   \n",
       "3             0  {'username': 'bobtimmermann', 'id': 17353087, ...        3   \n",
       "4             0  {'username': 'earthshook', 'id': 107816182, 'd...        3   \n",
       "\n",
       "          location  \n",
       "0            Earth  \n",
       "1                   \n",
       "2      San Juan PR  \n",
       "3  California, USA  \n",
       "4                   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_earthquake_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest_fire_en = df_forest_fire_en.drop('user', axis='columns')\n",
    "df_deforestation_en = df_deforestation_en.drop('user', axis='columns')\n",
    "df_flood_en = df_flood_en.drop('user', axis='columns')\n",
    "df_floodrain_en = df_floodrain_en.drop('user', axis='columns')\n",
    "df_floodwater_en = df_floodwater_en.drop('user', axis='columns')\n",
    "df_floodpour_en = df_floodpour_en.drop('user', axis='columns')\n",
    "df_eruption_en = df_eruption_en.drop('user', axis='columns')\n",
    "df_eruptionflow_en = df_eruptionflow_en.drop('user', axis='columns')\n",
    "df_aftershock_en = df_aftershock_en.drop('user', axis='columns')\n",
    "df_earthquake_en = df_earthquake_en.drop('user', axis='columns')\n",
    "df_flood_refugees_en = df_flood_refugees_en.drop('user', axis='columns')\n",
    "df_bunker_en = df_bunker_en.drop('user', axis='columns')\n",
    "df_earthquake_refugees_en = df_earthquake_refugees_en.drop('user', axis='columns')\n",
    "df_crop_drought_en = df_crop_drought_en.drop('user', axis='columns')\n",
    "df_tropical_cyclone_en = df_tropical_cyclone_en.drop('user', axis='columns')\n",
    "df_typhoon_en = df_typhoon_en.drop('user', axis='columns')\n",
    "df_hurricane_en = df_hurricane_en.drop('user', axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14601 entries, 0 to 499\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           14601 non-null  object             \n",
      " 1   date          14601 non-null  datetime64[ns, UTC]\n",
      " 2   rawContent    14601 non-null  object             \n",
      " 3   sourceLabel   14601 non-null  object             \n",
      " 4   retweetCount  14601 non-null  int64              \n",
      " 5   keyword       12601 non-null  float64            \n",
      " 6   location      14601 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(1), object(4)\n",
      "memory usage: 912.6+ KB\n"
     ]
    }
   ],
   "source": [
    "list_of_dataframes = [\n",
    "    df_forest_fire_en, \n",
    "    df_deforestation_en,\n",
    "    df_flood_en, \n",
    "    df_floodrain_en,\n",
    "    df_floodwater_en,\n",
    "    df_floodrain_en,\n",
    "    df_floodpour_en,\n",
    "    df_eruption_en, \n",
    "    df_eruptionflow_en,\n",
    "    df_aftershock_en,\n",
    "    df_earthquake_en, \n",
    "    df_flood_refugees_en, \n",
    "    df_bunker_en,\n",
    "    df_earthquake_refugees_en, \n",
    "    df_crop_drought_en,\n",
    "    df_tropical_cyclone_en,\n",
    "    df_typhoon_en,\n",
    "    df_hurricane_en,\n",
    "]\n",
    "\n",
    "df_tweets_en = pd.concat(list_of_dataframes)\n",
    "df_tweets_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_en.to_csv('./data/disaster_tweets_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scrape Tagalog tweets</h1>\n",
    "In this section, we will be scraping data in the language of Tagalog as stated in the language filter of twitter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Disasters\n",
    "\n",
    "df_climate_change_tl = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"climate change philippines\" ').get_items(), 10))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_climate_change_tl[\"keyword\"] = 4\n",
    "\n",
    "df_bagyo_tl = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"tropical cyclone bagyo\"').get_items(), 10))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_bagyo_tl[\"keyword\"] = 5\n",
    "\n",
    "df_baha_tl = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"flash flood\"').get_items(), 10))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_baha_tl[\"keyword\"] = 1\n",
    "\n",
    "df_earthquake_tl = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"lindol aftershock\" ').get_items(), 10))[['url', 'date', 'rawContent', 'sourceLabel', 'retweetCount',  'user']]\n",
    "df_earthquake_tl[\"keyword\"] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           10 non-null     object             \n",
      " 1   date          10 non-null     datetime64[ns, UTC]\n",
      " 2   rawContent    10 non-null     object             \n",
      " 3   sourceLabel   10 non-null     object             \n",
      " 4   retweetCount  10 non-null     int64              \n",
      " 5   user          10 non-null     object             \n",
      " 6   keyword       10 non-null     int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 688.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           10 non-null     object             \n",
      " 1   date          10 non-null     datetime64[ns, UTC]\n",
      " 2   rawContent    10 non-null     object             \n",
      " 3   sourceLabel   10 non-null     object             \n",
      " 4   retweetCount  10 non-null     int64              \n",
      " 5   user          10 non-null     object             \n",
      " 6   keyword       10 non-null     int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 688.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           10 non-null     object             \n",
      " 1   date          10 non-null     datetime64[ns, UTC]\n",
      " 2   rawContent    10 non-null     object             \n",
      " 3   sourceLabel   10 non-null     object             \n",
      " 4   retweetCount  10 non-null     int64              \n",
      " 5   user          10 non-null     object             \n",
      " 6   keyword       10 non-null     int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 688.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           10 non-null     object             \n",
      " 1   date          10 non-null     datetime64[ns, UTC]\n",
      " 2   rawContent    10 non-null     object             \n",
      " 3   sourceLabel   10 non-null     object             \n",
      " 4   retweetCount  10 non-null     int64              \n",
      " 5   user          10 non-null     object             \n",
      " 6   keyword       10 non-null     int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 688.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_climate_change_tl.info())\n",
    "print(df_bagyo_tl.info())\n",
    "print(df_baha_tl.info())\n",
    "print(df_earthquake_tl.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate_change_tl[\"location\"] = [user[\"location\"] for user in df_climate_change_tl[\"user\"]]\n",
    "df_bagyo_tl[\"location\"] = [user[\"location\"] for user in df_bagyo_tl[\"user\"]]\n",
    "df_baha_tl[\"location\"] = [user[\"location\"] for user in df_baha_tl[\"user\"]]\n",
    "df_earthquake_tl[\"location\"] = [user[\"location\"] for user in df_earthquake_tl[\"user\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>user</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/jmbeaucroft1/status/155243...</td>\n",
       "      <td>2022-07-27 23:07:04+00:00</td>\n",
       "      <td>Population overcrowding presents a major compo...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'jmbeaucroft1', 'id': 13936102283...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/PhilippinesApps/status/154...</td>\n",
       "      <td>2022-06-28 11:02:24+00:00</td>\n",
       "      <td>Ministry of Climate Change, #Philippines depar...</td>\n",
       "      <td>Philippines News App</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'PhilippinesApps', 'id': 78263399...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/Emirati_News/status/154173...</td>\n",
       "      <td>2022-06-28 11:00:19+00:00</td>\n",
       "      <td>Ministry of Climate Change, Philippines depart...</td>\n",
       "      <td>WordPress.com</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'Emirati_News', 'id': 12572090607...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/aoindependence/status/1541...</td>\n",
       "      <td>2022-06-27 10:59:46+00:00</td>\n",
       "      <td>The Philippines, with its worsening typhoons, ...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'aoindependence', 'id': 39904972,...</td>\n",
       "      <td>4</td>\n",
       "      <td>Woodbury Center, CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/notkathlynite/status/15213...</td>\n",
       "      <td>2022-05-03 02:48:37+00:00</td>\n",
       "      <td>so kahapon nag h2h kami, sabi nong isa kong ka...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>{'username': 'notkathlynite', 'id': 1443530688...</td>\n",
       "      <td>4</td>\n",
       "      <td>Area 51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://twitter.com/jmbeaucroft1/status/155243...   \n",
       "1  https://twitter.com/PhilippinesApps/status/154...   \n",
       "2  https://twitter.com/Emirati_News/status/154173...   \n",
       "3  https://twitter.com/aoindependence/status/1541...   \n",
       "4  https://twitter.com/notkathlynite/status/15213...   \n",
       "\n",
       "                       date  \\\n",
       "0 2022-07-27 23:07:04+00:00   \n",
       "1 2022-06-28 11:02:24+00:00   \n",
       "2 2022-06-28 11:00:19+00:00   \n",
       "3 2022-06-27 10:59:46+00:00   \n",
       "4 2022-05-03 02:48:37+00:00   \n",
       "\n",
       "                                          rawContent           sourceLabel  \\\n",
       "0  Population overcrowding presents a major compo...    Twitter for iPhone   \n",
       "1  Ministry of Climate Change, #Philippines depar...  Philippines News App   \n",
       "2  Ministry of Climate Change, Philippines depart...         WordPress.com   \n",
       "3  The Philippines, with its worsening typhoons, ...              LinkedIn   \n",
       "4  so kahapon nag h2h kami, sabi nong isa kong ka...   Twitter for Android   \n",
       "\n",
       "   retweetCount                                               user  keyword  \\\n",
       "0             0  {'username': 'jmbeaucroft1', 'id': 13936102283...        4   \n",
       "1             0  {'username': 'PhilippinesApps', 'id': 78263399...        4   \n",
       "2             0  {'username': 'Emirati_News', 'id': 12572090607...        4   \n",
       "3             0  {'username': 'aoindependence', 'id': 39904972,...        4   \n",
       "4             0  {'username': 'notkathlynite', 'id': 1443530688...        4   \n",
       "\n",
       "              location  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3  Woodbury Center, CT  \n",
       "4             Area 51   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_climate_change_tl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate_change_tl = df_climate_change_tl.drop('user', axis='columns')\n",
    "df_bagyo_tl = df_bagyo_tl.drop('user', axis='columns')\n",
    "df_baha_tl = df_baha_tl.drop('user', axis='columns')\n",
    "df_earthquake_tl = df_earthquake_tl.drop('user', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   url           40 non-null     object             \n",
      " 1   date          40 non-null     datetime64[ns, UTC]\n",
      " 2   rawContent    40 non-null     object             \n",
      " 3   sourceLabel   40 non-null     object             \n",
      " 4   retweetCount  40 non-null     int64              \n",
      " 5   keyword       40 non-null     int64              \n",
      " 6   location      40 non-null     object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "list_of_dataframes = [\n",
    "    df_climate_change_tl, \n",
    "    df_bagyo_tl, \n",
    "    df_baha_tl, \n",
    "    df_earthquake_tl, \n",
    "]\n",
    "\n",
    "df_tweets_tl = pd.concat(list_of_dataframes)\n",
    "df_tweets_tl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_tl.to_csv('./data/disaster_tweets_tl.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83d04032e859d7f6b4884d0eaea2daded37857bd69838437e04f68722128dc82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
