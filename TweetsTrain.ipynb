{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training the Classifier/Filter</h2>\n",
    "Currently we are trying to train the whole classifier with a single function, the train function. Next is we will call the pipeline to filter and  clean all the tweets we need to clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:  0.7883597883597884\n",
      "\n",
      "Classification Report for\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.82       434\n",
      "           1       0.79      0.68      0.73       322\n",
      "\n",
      "    accuracy                           0.79       756\n",
      "   macro avg       0.79      0.77      0.78       756\n",
      "weighted avg       0.79      0.79      0.79       756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from train.classifier import train\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.frequency import train as train_freq\n",
    "\n",
    "train_freq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tweet Cleaning</h2>\n",
    "This is where the real operation starts. We will filter the tweets based on the saved model, and clean them in a proper manner. The steps are as follows:\n",
    "\n",
    "* Filter Tweets (filter_pipeline)\n",
    "* Clean Tweets (data_pipeline)\n",
    "* format Tweets to pass in our model (data_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./saved_models/SVMClassifier.pkl\", 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass_report = classification_report(df_tweets_en[\"target\"], df_tweets_en[\"vote_pred\"])\\nprint(\\'\\n Accuracy: \\', accuracy_score(df_tweets_en[\"target\"], df_tweets_en[\"vote_pred\"]))\\nprint(\\'\\nClassification Report for\\')\\nprint(\\'======================================================\\')\\nprint(\\'\\n\\', class_report)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from train.classifier import *\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "df_tweets_en = pd.read_csv(\"./data/disaster_tweets_en.csv\")\n",
    "df_tweets_en[\"rawContent\"] = df_tweets_en[\"rawContent\"].astype(str)\n",
    "\n",
    "\n",
    "X_testset = Cleaner(\n",
    "        ds_train=df_tweets_en,\n",
    "        train_column=\"rawContent\",\n",
    "        test_column=\"keyword\",\n",
    "        type=\"test\",\n",
    "\n",
    "    ).X\n",
    "predictions = pickle_model.predict(X_testset)\n",
    "\n",
    "\n",
    "df_tweets_en[\"vote_pred\"] = predictions\n",
    "df_tweets_en.to_csv('./data/disaster_tweets_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Topic Segmentation</h2>\n",
    "This is where we segment tweets based on the frequency of the word that appears on the document, therefore classifying that word based on the frequency output.\n",
    "\n",
    "We will perform the following\n",
    "\n",
    "*  term frequencyâ€“inverse document frequency(TF-IDF) to transpose the words into vectors of frequency\n",
    "* 3 models to test\n",
    "    * Logistic Regression\n",
    "    * SGD Classfier\n",
    "    * SGD Modified Huber\n",
    "* Check the accuracy metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models/SGDHuberFreq.pkl\", 'rb') as file:\n",
    "    freq_model = pickle.load(file)\n",
    "\n",
    "print(type(freq_model))\n",
    "X_testset = Cleaner(\n",
    "        ds_train=df_tweets_en,\n",
    "        column=\"rawContent\"\n",
    "    ).fit_testset()\n",
    "\n",
    "predictions_freq = freq_model.predict(X_testset)\n",
    "\n",
    "df_tweets_en[\"class_pred\"] = predictions_freq\n",
    "\n",
    "class_report = classification_report(df_tweets_en[\"keyword\"], df_tweets_en[\"class_pred\"])\n",
    "print('\\n Accuracy: ', accuracy_score(df_tweets_en[\"keyword\"], df_tweets_en[\"class_pred\"]))\n",
    "print('\\nClassification Report for')\n",
    "print('======================================================')\n",
    "print('\\n', class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1,2,3,4,5,6])\n",
    "arr = arr.reshape(3,2)\n",
    "\n",
    "arr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83d04032e859d7f6b4884d0eaea2daded37857bd69838437e04f68722128dc82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
